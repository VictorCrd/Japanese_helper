{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_rows = 200\n",
    "pd.options.display.max_columns = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get subtitles (youtube)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JLPT_N5youtube-transcript-api doc \n",
    "https://pypi.org/project/youtube-transcript-api/#description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yt_sub(youtube_id):\n",
    "    st = YouTubeTranscriptApi.get_transcript(youtube_id, languages = ['ja'])\n",
    "    res = [ sub['text'] for sub in st ] \n",
    "    df = pd.DataFrame({'phrases':res})\n",
    "    df = df.replace('\\n',' ', regex=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Core_Japanese_Vocabulary_N5 = pd.read_csv(\"JLPT_Voca_csv/Core_Japanese_Vocabulary_N5.csv\", usecols = ['Expression'])\n",
    "Core_Japanese_Vocabulary_N4 = pd.read_csv(\"JLPT_Voca_csv/Core_Japanese_Vocabulary_N4.csv\")\n",
    "Core_Japanese_Vocabulary_N3 = pd.read_csv(\"JLPT_Voca_csv/Core_Japanese_Vocabulary_N3.csv\")\n",
    "Core_Japanese_Vocabulary_N2 = pd.read_csv(\"JLPT_Voca_csv/Core_Japanese_Vocabulary_N2.csv\")\n",
    "Core_Japanese_Vocabulary_N1 = pd.read_csv(\"JLPT_Voca_csv/Core_Japanese_Vocabulary_N1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Core_Japanese_Vocabulary_N5 = pd.read_csv(\"JLPT_Voca_csv/Core_Japanese_Vocabulary_N5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntwo_raw = pd.read_csv(\"JLPT_Voca_csv/N2.csv\", sep='\\t')\n",
    "Nfor_raw = pd.read_csv(\"JLPT_Voca_csv/N4.csv\", sep='\\t')\n",
    "Nfive_raw = pd.read_csv(\"JLPT_Voca_csv/N5.csv\", sep='\\t')\n",
    "\n",
    "Ntwo_raw = Ntwo_raw.drop(columns = ['Type', '#'])\n",
    "Nfor_raw = Nfor_raw.drop(columns = ['Type', '#'])\n",
    "Nfive_raw = Nfive_raw.drop(columns = ['Type', '#'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntwo_raw[\"Kana_Kanji\"] = Ntwo_raw[\"Kanji\"] \n",
    "Ntwo_raw[\"Kana_Kanji\"] = Ntwo_raw[\"Kana_Kanji\"].fillna(Ntwo_raw[\"Kana\"])\n",
    "\n",
    "Nfor_raw[\"Kana_Kanji\"] = Nfor_raw[\"Kanji\"] \n",
    "Nfor_raw[\"Kana_Kanji\"] = Nfor_raw[\"Kana_Kanji\"].fillna(Nfor_raw[\"Kana\"])\n",
    "\n",
    "Nfive_raw[\"Kana_Kanji\"] = Nfive_raw[\"Kanji\"] \n",
    "Nfive_raw[\"Kana_Kanji\"] = Nfive_raw[\"Kana_Kanji\"].fillna(Nfive_raw[\"Kana\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "passthree_raw = pd.read_csv(\"JLPT_Voca_csv/passjapanesetest.com_N3_Vocabulary.csv\", encoding = \"S-JIS\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "passfor_raw = pd.read_csv(\"JLPT_Voca_csv/passjapanesetest.com_N4_Vocabulary-sjis.csv\", encoding = \"S-JIS\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "passfive_raw = pd.read_csv(\"JLPT_Voca_csv/passjapanesetest.com_N5_Vocabulary.csv\", encoding = \"S-JIS\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "JLPT_N5 = pd.read_csv(\"JLPT_Voca_csv/JLPT_N5.csv\", sep='\\t') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "JLPT_N4 = pd.read_csv(\"JLPT_Voca_csv/JLPT_N4.csv\", sep='\\t') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "JLPT_N3 = pd.read_csv(\"JLPT_Voca_csv/JLPT_N3.csv\", sep='\\t') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "japanese_lemmas = pd.read_csv(\"JLPT_Voca_csv/japanese_lemmas.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLPT5 = pd.concat([Nfive_raw[\"Kana_Kanji\"], passfive_raw[\"Kanji\"], JLPT_N5[\"Japanese\"]], ignore_index = True).drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLPT4 = pd.concat([Nfor_raw[\"Kana_Kanji\"], passfor_raw[\"Kanji\"], JLPT_N4[\"Japanese\"]], ignore_index = True).drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLPT3 = pd.concat([passthree_raw[\"Kanji\"], JLPT_N3[\"Japanese\"]], ignore_index = True).drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLPT5 = pd.DataFrame({'vocab':NLPT5})\n",
    "NLPT4 = pd.DataFrame({'vocab':NLPT4})\n",
    "NLPT3 = pd.DataFrame({'vocab':NLPT3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLPT3[\"count\"] = 0\n",
    "NLPT4[\"count\"] = 0\n",
    "NLPT5[\"count\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocab</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ああ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>会う</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>青</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>青い</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>赤</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>二月</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>詰らない</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>お肉</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>出ます</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>伯母さん</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>848 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    vocab  count\n",
       "0      ああ      0\n",
       "1      会う      0\n",
       "2       青      0\n",
       "3      青い      0\n",
       "4       赤      0\n",
       "..    ...    ...\n",
       "843    二月      0\n",
       "844  詰らない      0\n",
       "845    お肉      0\n",
       "846   出ます      0\n",
       "847  伯母さん      0\n",
       "\n",
       "[848 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NLPT5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find nbr of NLPT word by level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words_in_text(df_words, df_subtitles, column_words):\n",
    "    \n",
    "    for i in range(0, len(df_words)):\n",
    "        df_words[\"count\"].loc[i] = len(df_subtitles[df_subtitles['phrases'].str.contains(df_words[column_words][i])])\n",
    "        lemmas_sum = np.count_nonzero(df_words[\"count\"])\n",
    "        \n",
    "    return lemmas_sum\n",
    "\n",
    "def sum_words_in_text(df_words, df_subtitles, column_words):\n",
    "    \n",
    "    for i in range(0, len(df_words)):\n",
    "        df_words[\"count\"].loc[i] = len(df_subtitles[df_subtitles['phrases'].str.contains(df_words[column_words][i])])\n",
    "        lemmas_sum = df_words[\"count\"].sum()\n",
    "        \n",
    "    return lemmas_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JLPT_lvl(df_subtitles):\n",
    "    NLPT3[\"count\"], NLPT4[\"count\"], NLPT5[\"count\"] = 0, 0, 0\n",
    "    NLPT3_sum, NLPT4_sum, NLPT5_sum = 0, 0, 0\n",
    "    \n",
    "    NLPT5_sum = sum_words_in_text(NLPT5, df_subtitles, \"vocab\")  \n",
    "    NLPT4_sum = sum_words_in_text(NLPT4, df_subtitles, \"vocab\")  \n",
    "    NLPT3_sum = sum_words_in_text(NLPT3, df_subtitles, \"vocab\")  \n",
    "\n",
    "    return NLPT3_sum, NLPT4_sum, NLPT5_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Core_Japanese_Vocabulary_N5[\"count\"] = 0\n",
    "Core_Japanese_Vocabulary_N4[\"count\"] = 0\n",
    "Core_Japanese_Vocabulary_N3[\"count\"] = 0\n",
    "Core_Japanese_Vocabulary_N2[\"count\"] = 0\n",
    "Core_Japanese_Vocabulary_N1[\"count\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JLPT_lvl_Core(df_subtitles, column_words, cnt_sum = 0):\n",
    "    NLPT3[\"count\"], NLPT4[\"count\"], NLPT5[\"count\"] = 0, 0, 0\n",
    "    NLPT3_sum, NLPT4_sum, NLPT5_sum = 0, 0, 0\n",
    "    \n",
    "    if cnt_sum == 0 :\n",
    "        print(\"Count\")\n",
    "        CORE_N5_sum = count_words_in_text(Core_Japanese_Vocabulary_N5, df_subtitles, \"Expression\")/len(Core_Japanese_Vocabulary_N5)\n",
    "        CORE_N4_sum = count_words_in_text(Core_Japanese_Vocabulary_N4, df_subtitles, \"Expression\")/len(Core_Japanese_Vocabulary_N4)\n",
    "        CORE_N3_sum = count_words_in_text(Core_Japanese_Vocabulary_N3, df_subtitles, \"Expression\")/len(Core_Japanese_Vocabulary_N3)\n",
    "        CORE_N2_sum = count_words_in_text(Core_Japanese_Vocabulary_N2, df_subtitles, \"Expression\")/len(Core_Japanese_Vocabulary_N2)\n",
    "        CORE_N1_sum = count_words_in_text(Core_Japanese_Vocabulary_N1, df_subtitles, \"Expression\")/len(Core_Japanese_Vocabulary_N1)\n",
    "        \n",
    "    if cnt_sum == 1 :\n",
    "        print(\"Sum\")\n",
    "        CORE_N5_sum = sum_words_in_text(Core_Japanese_Vocabulary_N5, df_subtitles, \"Expression\")\n",
    "        CORE_N4_sum = sum_words_in_text(Core_Japanese_Vocabulary_N4, df_subtitles, \"Expression\")\n",
    "        CORE_N3_sum = sum_words_in_text(Core_Japanese_Vocabulary_N3, df_subtitles, \"Expression\")\n",
    "        CORE_N2_sum = sum_words_in_text(Core_Japanese_Vocabulary_N2, df_subtitles, \"Expression\")\n",
    "        CORE_N1_sum = sum_words_in_text(Core_Japanese_Vocabulary_N1, df_subtitles, \"Expression\")\n",
    "        \n",
    "    return CORE_N5_sum, CORE_N4_sum, CORE_N3_sum, CORE_N2_sum, CORE_N1_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\happy\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "c:\\users\\happy\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\strings.py:1954: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(396, 221, 224)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JLPT_lvl(get_yt_sub(\"unxNWKq9aUQ\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(285, 183, 239)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JLPT_lvl(get_yt_sub(\"op1ld6Mrqzg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0871559633027523,\n",
       " 0.0743362831858407,\n",
       " 0.06021104903786468,\n",
       " 0.004369538077403246,\n",
       " 0.014936519790888723)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JLPT_lvl_Core(get_yt_sub(\"unxNWKq9aUQ\"), \"Expression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.06574923547400612,\n",
       " 0.02831858407079646,\n",
       " 0.019863438857852266,\n",
       " 0.0018726591760299626,\n",
       " 0.004107542942494399)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JLPT_lvl_Core(get_yt_sub(\"op1ld6Mrqzg\"), \"Expression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0871559633027523,\n",
       " 0.0743362831858407,\n",
       " 0.06021104903786468,\n",
       " 0.004369538077403246,\n",
       " 0.014936519790888723)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JLPT_lvl_Core(get_yt_sub(\"unxNWKq9aUQ\"), \"Expression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.06574923547400612,\n",
       " 0.02831858407079646,\n",
       " 0.019863438857852266,\n",
       " 0.0018726591760299626,\n",
       " 0.004107542942494399)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JLPT_lvl_Core(get_yt_sub(\"op1ld6Mrqzg\"), \"Expression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(455, 245, 373, 33, 132)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JLPT_lvl_Core(get_yt_sub(\"pKXDZgvHW78\"), \"Expression\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2018348623853211,\n",
       " 0.13097345132743363,\n",
       " 0.07572936064556177,\n",
       " 0.01373283395755306,\n",
       " 0.02128454070201643)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JLPT_lvl_Core(get_yt_sub(\"pKXDZgvHW78\"), \"Expression\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_removed_lemma = \"の|に|は|て|を|が|だ|た|と|で|も|a|b|c|d|e|f|g|h|i|j|k|l|m|n|o|p|q|r|s|t|u|v|w|x|y|z|!|:|・|「|」|！|？\"\n",
    "japanese_lemmas = japanese_lemmas[~japanese_lemmas.lemma.str.contains(list_removed_lemma)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>frequency</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>16841.17</td>\n",
       "      <td>する</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>9604.49</td>\n",
       "      <td>ます</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>8189.00</td>\n",
       "      <td>ない</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>8140.22</td>\n",
       "      <td>いる</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>6766.19</td>\n",
       "      <td>ある</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14993</th>\n",
       "      <td>14995</td>\n",
       "      <td>2.24</td>\n",
       "      <td>摘む</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>14996</td>\n",
       "      <td>2.24</td>\n",
       "      <td>夕べ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>14997</td>\n",
       "      <td>2.24</td>\n",
       "      <td>売場</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>14999</td>\n",
       "      <td>2.24</td>\n",
       "      <td>かしこ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>15000</td>\n",
       "      <td>2.24</td>\n",
       "      <td>バックグラウンド</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14013 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rank  frequency     lemma\n",
       "8          9   16841.17        する\n",
       "10        11    9604.49        ます\n",
       "12        13    8189.00        ない\n",
       "13        14    8140.22        いる\n",
       "15        16    6766.19        ある\n",
       "...      ...        ...       ...\n",
       "14993  14995       2.24        摘む\n",
       "14994  14996       2.24        夕べ\n",
       "14995  14997       2.24        売場\n",
       "14997  14999       2.24       かしこ\n",
       "14998  15000       2.24  バックグラウンド\n",
       "\n",
       "[14013 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "japanese_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "japanese_lemmas = japanese_lemmas.reset_index(drop = True)\n",
    "lemmas_5 = japanese_lemmas[0:200].copy()\n",
    "lemmas_4 = japanese_lemmas[200:1000].copy().reset_index(drop = True)\n",
    "lemmas_3 = japanese_lemmas[1000:3000].copy().reset_index(drop = True)\n",
    "lemmas_2 = japanese_lemmas[3000:15000].copy().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>frequency</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1155</td>\n",
       "      <td>65.64</td>\n",
       "      <td>残す</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1156</td>\n",
       "      <td>65.61</td>\n",
       "      <td>教授</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1157</td>\n",
       "      <td>65.52</td>\n",
       "      <td>さえ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1158</td>\n",
       "      <td>65.44</td>\n",
       "      <td>戦略</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1159</td>\n",
       "      <td>65.42</td>\n",
       "      <td>営業</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>3322</td>\n",
       "      <td>19.62</td>\n",
       "      <td>田舎</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>3323</td>\n",
       "      <td>19.62</td>\n",
       "      <td>任せる</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>3324</td>\n",
       "      <td>19.61</td>\n",
       "      <td>鍵</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>3325</td>\n",
       "      <td>19.60</td>\n",
       "      <td>勿論</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>3326</td>\n",
       "      <td>19.60</td>\n",
       "      <td>指す</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rank  frequency lemma\n",
       "0     1155      65.64    残す\n",
       "1     1156      65.61    教授\n",
       "2     1157      65.52    さえ\n",
       "3     1158      65.44    戦略\n",
       "4     1159      65.42    営業\n",
       "...    ...        ...   ...\n",
       "1995  3322      19.62    田舎\n",
       "1996  3323      19.62   任せる\n",
       "1997  3324      19.61     鍵\n",
       "1998  3325      19.60    勿論\n",
       "1999  3326      19.60    指す\n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_5[\"count\"] = 0\n",
    "lemmas_4[\"count\"] = 0\n",
    "lemmas_3[\"count\"] = 0\n",
    "lemmas_2[\"count\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JLPT_lvl_lemmas(df_subtitles, column_words, cnt_sum = 0):\n",
    "    lemmas_5[\"count\"], lemmas_4[\"count\"], lemmas_3[\"count\"], lemmas_2[\"count\"] = 0, 0, 0, 0\n",
    "    lemmas_5_sum, lemmas_4_sum, lemmas_3_sum, lemmas_2_sum = 0, 0, 0, 0\n",
    "    \n",
    "    if cnt_sum == 0 :\n",
    "        lemmas_5_sum = count_words_in_text(lemmas_5, df_subtitles, column_words)\n",
    "        lemmas_4_sum = count_words_in_text(lemmas_4, df_subtitles, column_words)\n",
    "        lemmas_3_sum = count_words_in_text(lemmas_3, df_subtitles, column_words)\n",
    "        lemmas_2_sum = count_words_in_text(lemmas_2, df_subtitles, column_words)\n",
    "        \n",
    "    if cnt_sum == 1 :\n",
    "        lemmas_5_sum = sum_words_in_text(lemmas_5, df_subtitles, column_words)\n",
    "        lemmas_4_sum = sum_words_in_text(lemmas_4, df_subtitles, column_words)\n",
    "        lemmas_3_sum = sum_words_in_text(lemmas_3, df_subtitles, column_words)\n",
    "        lemmas_2_sum = sum_words_in_text(lemmas_2, df_subtitles, column_words)\n",
    "\n",
    "    return lemmas_5_sum, lemmas_4_sum, lemmas_3_sum, lemmas_2_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\happy\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(80, 132, 120, 181)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JLPT_lvl_lemmas(get_yt_sub(\"unxNWKq9aUQ\"),\"lemma\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(617, 574, 413, 355)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JLPT_lvl_lemmas(get_yt_sub(\"unxNWKq9aUQ\"),\"lemma\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 49, 64, 121)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JLPT_lvl_lemmas(get_yt_sub(\"op1ld6Mrqzg\"),\"lemma\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(630, 636, 593, 469)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JLPT_lvl_lemmas(get_yt_sub(\"op1ld6Mrqzg\"),\"lemma\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Expression</th>\n",
       "      <th>Meaning</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Grammar</th>\n",
       "      <th>Additional_meaning</th>\n",
       "      <th>Marqueurs</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>夏</td>\n",
       "      <td>summer</td>\n",
       "      <td>夏[なつ]</td>\n",
       "      <td>Adverbial noun, Temporal noun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jlpt-n5 jlpt-n5</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>好き</td>\n",
       "      <td>liked, well-liked, favourite, favorite</td>\n",
       "      <td>好[す]き</td>\n",
       "      <td>Na-adjective, Noun</td>\n",
       "      <td>in love (with), loved, romantically interested...</td>\n",
       "      <td>jlpt-n5 jlpt-n5</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>人</td>\n",
       "      <td>man, person</td>\n",
       "      <td>人[ひと]</td>\n",
       "      <td>Noun</td>\n",
       "      <td>human being, mankind, people; human (Homo sapi...</td>\n",
       "      <td>jlpt-n5 jlpt-n5</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>本</td>\n",
       "      <td>book, volume, script</td>\n",
       "      <td>本[ほん]</td>\n",
       "      <td>Noun</td>\n",
       "      <td>this, present; main, head; real, regular; coun...</td>\n",
       "      <td>jlpt-n5 jlpt-n5</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>でも</td>\n",
       "      <td>but, however, though, nevertheless, still, yet...</td>\n",
       "      <td>でも</td>\n",
       "      <td>Conjunction</td>\n",
       "      <td>even; however, no matter how, even if, even th...</td>\n",
       "      <td>jlpt-n3 jlpt-n5 jlpt-n3 jlpt-n5</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>兄</td>\n",
       "      <td>elder brother, older brother</td>\n",
       "      <td>兄[あに]</td>\n",
       "      <td>Noun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jlpt-n5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>有名</td>\n",
       "      <td>famous</td>\n",
       "      <td>有名[ゆうめい]</td>\n",
       "      <td>Na-adjective</td>\n",
       "      <td>fame</td>\n",
       "      <td>jlpt-n5 jlpt-n5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>夕べ</td>\n",
       "      <td>evening</td>\n",
       "      <td>夕[ゆう]べ</td>\n",
       "      <td>Adverbial noun, Temporal noun</td>\n",
       "      <td>last night, yesterday evening</td>\n",
       "      <td>jlpt-n3 jlpt-n5 jlpt-n3 jlpt-n5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>質問</td>\n",
       "      <td>question, inquiry, enquiry</td>\n",
       "      <td>質問[しつもん]</td>\n",
       "      <td>Noun, Suru verb, No-adjective</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jlpt-n5 jlpt-n5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>ＰＥＴ</td>\n",
       "      <td>polyethylene terephthalate, PET</td>\n",
       "      <td>ＰＥＴ</td>\n",
       "      <td>Noun</td>\n",
       "      <td>positron emission tomography, PET</td>\n",
       "      <td>jlpt-n5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>654 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Expression                                            Meaning   Reading  \\\n",
       "46           夏                                             summer     夏[なつ]   \n",
       "382         好き             liked, well-liked, favourite, favorite     好[す]き   \n",
       "374          人                                        man, person     人[ひと]   \n",
       "379          本                               book, volume, script     本[ほん]   \n",
       "519         でも  but, however, though, nevertheless, still, yet...        でも   \n",
       "..         ...                                                ...       ...   \n",
       "244          兄                       elder brother, older brother     兄[あに]   \n",
       "243         有名                                             famous  有名[ゆうめい]   \n",
       "242         夕べ                                            evening    夕[ゆう]べ   \n",
       "241         質問                         question, inquiry, enquiry  質問[しつもん]   \n",
       "653        ＰＥＴ                    polyethylene terephthalate, PET       ＰＥＴ   \n",
       "\n",
       "                           Grammar  \\\n",
       "46   Adverbial noun, Temporal noun   \n",
       "382             Na-adjective, Noun   \n",
       "374                           Noun   \n",
       "379                           Noun   \n",
       "519                    Conjunction   \n",
       "..                             ...   \n",
       "244                           Noun   \n",
       "243                   Na-adjective   \n",
       "242  Adverbial noun, Temporal noun   \n",
       "241  Noun, Suru verb, No-adjective   \n",
       "653                           Noun   \n",
       "\n",
       "                                    Additional_meaning  \\\n",
       "46                                                 NaN   \n",
       "382  in love (with), loved, romantically interested...   \n",
       "374  human being, mankind, people; human (Homo sapi...   \n",
       "379  this, present; main, head; real, regular; coun...   \n",
       "519  even; however, no matter how, even if, even th...   \n",
       "..                                                 ...   \n",
       "244                                                NaN   \n",
       "243                                               fame   \n",
       "242                      last night, yesterday evening   \n",
       "241                                                NaN   \n",
       "653                  positron emission tomography, PET   \n",
       "\n",
       "                           Marqueurs  count  \n",
       "46                   jlpt-n5 jlpt-n5     26  \n",
       "382                  jlpt-n5 jlpt-n5     23  \n",
       "374                  jlpt-n5 jlpt-n5     22  \n",
       "379                  jlpt-n5 jlpt-n5     20  \n",
       "519  jlpt-n3 jlpt-n5 jlpt-n3 jlpt-n5     13  \n",
       "..                               ...    ...  \n",
       "244                          jlpt-n5      0  \n",
       "243                  jlpt-n5 jlpt-n5      0  \n",
       "242  jlpt-n3 jlpt-n5 jlpt-n3 jlpt-n5      0  \n",
       "241                  jlpt-n5 jlpt-n5      0  \n",
       "653                          jlpt-n5      0  \n",
       "\n",
       "[654 rows x 7 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Core_Japanese_Vocabulary_N5.sort_values(\"count\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subs = \"皆さん、こんにちは、日本語の先生のりこです。今日も楽しく日本語の勉強してますか。今日は、中級の教科書について話します。上級へのとびら、上級へのとびらという教科書について知っていますか。私の生徒さんの中でも、初級を終わって、中級、そして、中級から上級へのステップアップとして、この上級へのとびらを使っている生徒さんがたくさんいます。私は個人的にこの教科書が好きです。まず、読み物、読み物のコンテンツがとても充実していると思います。日本のいろいろな文化について書いてありますが、本当にコンテンツが詳しく書いてあります。読み応えがあります。でも、初級の教科書を終わったばかりの生徒さんにとっては、ものすごく難しく感じるかもしれません。なぜならそのコンテンツは長いし、難しい言葉、新しい言葉がたくさん出てくるからです。でも、読むことが好き、日本の文化を知りたい、もっと新しい言葉、漢字を覚えたいという生徒さんには、とてもお勧めができます。単語のリストや文法も詳しいと思います。そこで、今回から、少しずつ上級へのとびらに出てくるトピックや言葉を使って、色々話してみたいと思います。今日は第一課ですね。上級へのとびらの第一課に出てくる、あなたの国または出身地の名所と名物について話しましょう、書きましょう、ということについて話します。あなたの国、私の場合、日本です。出身地、私の場合、岡山県の倉敷です。その名所と名物。わかりますか。名所名物。名所は、名前の「名」と場所の「所」で名所。これは、その土地の有名な所、よく知られているところ、たくさんの観光客が行くところ。または最近できた話題のスポットかもしれません。名物は、名前の「名」、そして、「物」の「もの」ですね。名物。これはその土地で有名なもの、食べ物かもしれないし、食べ物じゃない時もあると思います。それが名物、その土地のもの。皆さんの出身地の名所と名物は何ですか。それについて是非考えてみて、文章で書いてみたり、話したりしてみてください。日本語で書いてみましょう。私の場合、倉敷市について話します。倉敷市の名所は倉敷市の駅の近くにある美術館、大原美術館です。この大原美術館は、倉敷の美観地区の中にあります。小さい美術館なんですが、とても有名なんです。どうしてかというと、ロダンとかピカソとかモネとか、実はすごく有名な人の作品がたくさんあるんです。こんなところにこんな絵があるの、とびっくりするような素晴らしいコレクションです。もし岡山県の倉敷市に来る機会があれば、必ず大原美術館に行ってみてください。私は子供の時からよく行っていました。小学校での遠足、おかあさんといっしょに行ったり、また大人になって友達と行ったり、何回も言ったことがあります。行くたびに何か新しい発見、勉強ができる素晴らしい美術館だと思います。ということで倉敷市の名所は大原美術館。私にとっては大原美術館です。じゃあ、倉敷の名物。私なら、ぶっかけうどんと答えます。これも倉敷市の駅の近くにレストラン、ま、うどん屋さんがあって、その名前が倉敷ぶっかけうどんと言います。今ではもうとても有名で成功して、倉敷のどこにでもあります。チェーンになりました。でも味は変わってないです。とても美味しいで す。うどんがすきなら、おすすめです。私は倉敷市に戻ると、必ず絶対にこのうどんを食べに行きます。倉敷の名物はぶっかけうどんです。じゃあ、皆さんの出身地の名所と名物を教えてください。今日のトピックは、上級へのとびら第一課から、名所と名物について取り上げました。このシリーズまた続けます。上級へのとびらの中に出てくる、コンテンツや単語を使って話していきたいと思います。じゃあ、皆さんまたね\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今日 も 楽しく 日本 語 の 勉強 し て ます か\n"
     ]
    }
   ],
   "source": [
    "import fugashi\n",
    "\n",
    "# This is our sample text.\n",
    "# \"Fugashi\" is a Japanese snack primarily made of gluten.\n",
    "text = \"今日も楽しく日本語の勉強してますか\"\n",
    "\n",
    "# The Tagger object holds state about the dictionary. \n",
    "tagger = fugashi.Tagger()\n",
    "words = [word.surface for word in tagger(text)]\n",
    "print(*words)\n",
    "# => 麩 菓子 は 、 麩 を 主材 料 と し た 日本 の 菓子 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 今日も楽しく日本語の勉強してますか。\n",
      "今日\t今日\n",
      "も\tも\n",
      "楽しく\t楽しい\n",
      "日本\t日本\n",
      "語\t語\n",
      "の\tの\n",
      "勉強\t勉強\n",
      "し\t為る\n",
      "て\tてる\n",
      "ます\tます\n",
      "か\tか\n",
      "。\t。\n"
     ]
    }
   ],
   "source": [
    "import fugashi\n",
    "tagger = fugashi.Tagger()\n",
    "text = \"今日も楽しく日本語の勉強してますか。\"\n",
    "\n",
    "print(\"input:\", text)\n",
    "for word in tagger(text):\n",
    "    # feature is a named tuple holding all the Unidic info\n",
    "    print(word.surface, word.feature.lemma, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'為る'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger(\"してます\")[0].feature.lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 麩を用いた菓子は江戸時代からすでに存在していた。\n",
      "麩\t麩\n",
      "を\tを\n",
      "用い\t用いる\n",
      "た\tた\n",
      "菓子\t菓子\n",
      "は\tは\n",
      "江戸\tエド\n",
      "時代\t時代\n",
      "から\tから\n",
      "すでに\t既に\n",
      "存在\t存在\n",
      "し\t為る\n",
      "て\tて\n",
      "い\t居る\n",
      "た\tた\n",
      "。\t。\n"
     ]
    }
   ],
   "source": [
    "text = \"麩を用いた菓子は江戸時代からすでに存在していた。\"\n",
    "\n",
    "print(\"input:\", text)\n",
    "for word in tagger(text):\n",
    "    # feature is a named tuple holding all the Unidic info\n",
    "    print(word.surface, word.feature.lemma, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words_in_text_pod(df_words, df_subtitles, column_words):\n",
    "\n",
    "    df_words[\"count\"].loc[i] = len(df_subtitles[df_subtitles['phrases'].str.contains(df_words[column_words][i])])\n",
    "    lemmas_sum = np.count_nonzero(df_words[\"count\"])\n",
    "        \n",
    "    return lemmas_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JLPT_lvl_pod(df_subtitles, column_words, cnt_sum = 0):\n",
    "    NLPT3[\"count\"], NLPT4[\"count\"], NLPT5[\"count\"] = 0, 0, 0\n",
    "    NLPT3_sum, NLPT4_sum, NLPT5_sum = 0, 0, 0\n",
    "    \n",
    "    if cnt_sum == 0 :\n",
    "        print(\"Count\")\n",
    "        CORE_N5_sum = count_words_in_text(Core_Japanese_Vocabulary_N5, df_subtitles, \"Expression\")/len(Core_Japanese_Vocabulary_N5)\n",
    "        CORE_N4_sum = count_words_in_text(Core_Japanese_Vocabulary_N4, df_subtitles, \"Expression\")/len(Core_Japanese_Vocabulary_N4)\n",
    "        CORE_N3_sum = count_words_in_text(Core_Japanese_Vocabulary_N3, df_subtitles, \"Expression\")/len(Core_Japanese_Vocabulary_N3)\n",
    "        CORE_N2_sum = count_words_in_text(Core_Japanese_Vocabulary_N2, df_subtitles, \"Expression\")/len(Core_Japanese_Vocabulary_N2)\n",
    "        CORE_N1_sum = count_words_in_text(Core_Japanese_Vocabulary_N1, df_subtitles, \"Expression\")/len(Core_Japanese_Vocabulary_N1)\n",
    "        \n",
    "    if cnt_sum == 1 :\n",
    "        print(\"Sum\")\n",
    "        CORE_N5_sum = sum_words_in_text(Core_Japanese_Vocabulary_N5, df_subtitles, \"Expression\")\n",
    "        CORE_N4_sum = sum_words_in_text(Core_Japanese_Vocabulary_N4, df_subtitles, \"Expression\")\n",
    "        CORE_N3_sum = sum_words_in_text(Core_Japanese_Vocabulary_N3, df_subtitles, \"Expression\")\n",
    "        CORE_N2_sum = sum_words_in_text(Core_Japanese_Vocabulary_N2, df_subtitles, \"Expression\")\n",
    "        CORE_N1_sum = sum_words_in_text(Core_Japanese_Vocabulary_N1, df_subtitles, \"Expression\")\n",
    "        \n",
    "    return CORE_N5_sum, CORE_N4_sum, CORE_N3_sum, CORE_N2_sum, CORE_N1_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "if \"皆さん\" in Subs: \n",
    "   print('success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_subtitles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-3c91774919ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_subtitles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_subtitles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'phrases'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_words\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn_words\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_subtitles' is not defined"
     ]
    }
   ],
   "source": [
    "len(df_subtitles[df_subtitles['phrases'].str.contains(df_words[column_words][i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "JLPT_lvl_Core(Subs, \"Expression\", 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
